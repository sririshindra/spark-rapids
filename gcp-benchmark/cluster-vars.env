#!/bin/bash

export HOME_DIR=/home/$USER

export CLUSTER_NAME="$1"

export ZONE=us-central1-a

export NUM_GPUS_IN_MASTER=2

export NUM_GPUS_IN_WORKER=2

export NUM_WORKERS=5

export MASTER=$CLUSTER_NAME-m

export WORKERS=$(seq -f "$CLUSTER_NAME-w-%g" 0 $(($NUM_WORKERS-1)))

export DATAPROC_BUCKET=dataproc-initialization-actions

export ETL_BUCKET="$2"

export SPARK_TGZ="$3"

#set this variable to location of cudf and rapids plugin jars to be made available during spark-shell initialization separated by spaces
export SHIPPED_JARS=""
